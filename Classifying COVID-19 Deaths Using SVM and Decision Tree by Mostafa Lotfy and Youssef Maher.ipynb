{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.metrics import  recall_score,roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "import itertools\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cleaning\n",
    "By inspecting the values in the different columns we noticed some irregular values especially in the gender and diff_sym_hos columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Negative hours changed to positive\n",
    "for i in range(len(df)):\n",
    "    df.iloc[i, 12] = df.iloc[i, 12] * -1 if df.iloc[i, 12] < 0 else df.iloc[i, 12]\n",
    "\n",
    "#Gender value 2 changed to the most common gender\n",
    "df['gender'] = df['gender'].mask(df['gender'] == 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Helper Methods\n",
    "These methods will be used to perform different operations such as encoding the data. As well as splitting the dataframe to train, test, and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Splits the given dataframe into 70% training set, 15% validation set, 15% testing set\n",
    "def split(df):\n",
    "    x = df.drop('result', axis=1)\n",
    "    y = df['result']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,shuffle=True, random_state=42, stratify=y)\n",
    "    X_validate, X_test, y_validate, y_test = train_test_split(X_test, y_test, test_size=0.5,shuffle=True, random_state=42, stratify=y_test)\n",
    "    return X_train, X_validate, X_test, y_train, y_validate, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "def encode(df, columns):\n",
    "    df_encoded = df.copy()\n",
    "    for col in columns:\n",
    "        encoding = pd.get_dummies(df[col], prefix=col)\n",
    "        df_encoded = df_encoded.join(encoding)\n",
    "        df_encoded.drop(col, axis=1, inplace=True)\n",
    "    return df_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method will take the training and validation data, perform hyperparameter tuning and evaluate based on the best recall from the different models for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def svm_validate(X_train, y_train, X_validate, y_validate):\n",
    "    dic = {'clf':[], 'recall':[]}\n",
    "    # Regularization parameter. The strength of the regularization \n",
    "    # is inversely proportional to C\n",
    "    c_values = [0.1, 1, 10, 100, 1000]\n",
    "    \n",
    "    #Kernel coefficient for ‘rbf’\n",
    "    gamma_values = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "    \n",
    "    #Degree of the polynomial kernel function\n",
    "    degrees = np.arange(1, 11, 1)\n",
    "\n",
    "    parameters = list(itertools.product(c_values, gamma_values, degrees))\n",
    "    for c, gamma, degree in parameters:\n",
    "        \n",
    "        #Perform scaling on the data then fit the model\n",
    "        rbf_kernel_svm_clf = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svm_clf\", SVC(C=c, gamma=gamma, degree=degree, random_state= 2))\n",
    "        ])\n",
    "        rbf_kernel_svm_clf.fit(X_train, y_train)\n",
    "        y_pred = rbf_kernel_svm_clf.predict(X_validate)\n",
    "        recall = recall_score(y_validate, y_pred)\n",
    "        dic['clf'].append(rbf_kernel_svm_clf)\n",
    "        dic['recall'].append(recall)\n",
    "    df_scores = pd.DataFrame(dic)\n",
    "    return df_scores.iloc[df_scores['recall'].idxmax(), 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method will take the training and validation data, perform hyperparameter tuning and evaluate based on the best recall from the different models for DT. More hyperparameters were tested (such as max_depth) but they resulted in worse metrics thus they were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_validate(X_train, y_train, X_validate, y_validate):\n",
    "    dic = {'clf':[], 'recall':[]}\n",
    "    \n",
    "    # The function to measure the quality of a split.\n",
    "    criterion = ['entropy','gini']\n",
    "    \n",
    "    # The strategy used to choose the split at each node.\n",
    "    splitter = ['best','random']\n",
    "    \n",
    "    # Weights associated with classes\n",
    "    class_weight = ['balanced',None]\n",
    "    \n",
    "    # The number of features to consider when looking for the best split\n",
    "    max_features = [i for i in range(1,X_train.shape[1])]\n",
    "    \n",
    "    parameters = list(itertools.product(criterion, splitter, class_weight, max_features))\n",
    "    for crit, splitter, weight, max_features in parameters:\n",
    "        DT = DecisionTreeClassifier(criterion = crit, splitter=splitter, class_weight=weight, max_features=max_features, random_state=2)\n",
    "        DT.fit(X_train, y_train)\n",
    "        y_pred = DT.predict(X_validate)\n",
    "        recall = recall_score(y_validate, y_pred)\n",
    "        dic['clf'].append(DT)\n",
    "        dic['recall'].append(recall)\n",
    "    df_scores = pd.DataFrame(dic)\n",
    "    return df_scores.iloc[df_scores['recall'].idxmax(), 0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Without Encoding\n",
    "First we attempt to fit the model without any changes to act as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('svm_clf', SVC(C=10, degree=1, gamma=0.1, random_state=2))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       114\n",
      "           1       0.81      0.81      0.81        16\n",
      "\n",
      "    accuracy                           0.95       130\n",
      "   macro avg       0.89      0.89      0.89       130\n",
      "weighted avg       0.95      0.95      0.95       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test = split(df)\n",
    "best_svm = svm_validate(X_train, y_train, X_validate, y_validate)\n",
    "print(best_svm)\n",
    "print(classification_report(y_test, best_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Encoding\n",
    "We then encode some of the categorical data in the dataset to improve the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('svm_clf', SVC(C=100, degree=1, gamma=0.001, random_state=2))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       114\n",
      "           1       1.00      0.75      0.86        16\n",
      "\n",
      "    accuracy                           0.97       130\n",
      "   macro avg       0.98      0.88      0.92       130\n",
      "weighted avg       0.97      0.97      0.97       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['location', 'country', 'symptom1', 'symptom2', 'symptom3', 'symptom4', 'symptom5', 'symptom6']\n",
    "df_encoded = encode(df, cols)\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = split(df_encoded)\n",
    "best_svm = svm_validate(X_train, y_train, X_validate, y_validate)\n",
    "print(best_svm)\n",
    "print(classification_report(y_test, best_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature selection\n",
    "Here we experimentally select features. After some experiments this is the best result. Some features were removed based on their low correlation with the data while others were removed after experimentally testing that their removal improved recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('svm_clf', SVC(C=100, degree=1, gamma=0.001, random_state=2))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       114\n",
      "           1       0.93      0.88      0.90        16\n",
      "\n",
      "    accuracy                           0.98       130\n",
      "   macro avg       0.96      0.93      0.95       130\n",
      "weighted avg       0.98      0.98      0.98       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_cols = ['symptom6', 'symptom5', 'symptom4','symptom2']\n",
    "encoded_cols = ['country','location', 'symptom1', 'symptom3']\n",
    "df_encoded = encode(df.drop(dropped_cols, axis=1), encoded_cols)\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = split(df_encoded)\n",
    "best_svm = svm_validate(X_train, y_train, X_validate, y_validate)\n",
    "print(best_svm)\n",
    "print(classification_report(y_test, best_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bagging with Validation\n",
    "In this section, we utilise a bagging classifier to attempt to improve the recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dic = {'clf':[], 'recall':[]}\n",
    "c_values = [0.1, 1, 10, 100, 1000] \n",
    "gamma_values = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "degrees = np.arange(1, 11, 1)\n",
    "\n",
    "parameters = list(itertools.product(c_values, gamma_values, degrees))\n",
    "for c, gamma, degree in parameters:\n",
    "    rbf_kernel_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(C=c, gamma=gamma, degree=degree, random_state = 2))\n",
    "    ])\n",
    "    bagging_clf = BaggingClassifier(base_estimator=rbf_kernel_svm_clf, n_estimators=10, random_state=2)\n",
    "    bagging_clf.fit(X_train, y_train)\n",
    "    y_pred = bagging_clf.predict(X_validate)\n",
    "    recall = recall_score(y_validate, y_pred)\n",
    "    dic['clf'].append(bagging_clf)\n",
    "    dic['recall'].append(recall)\n",
    "df_scores = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                                                 ('svm_clf',\n",
      "                                                  SVC(C=10, degree=1,\n",
      "                                                      gamma=0.01,\n",
      "                                                      random_state=2))]),\n",
      "                  random_state=2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       114\n",
      "           1       0.91      0.62      0.74        16\n",
      "\n",
      "    accuracy                           0.95       130\n",
      "   macro avg       0.93      0.81      0.86       130\n",
      "weighted avg       0.94      0.95      0.94       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bagging_clf = df_scores.iloc[df_scores['recall'].idxmax(), 0]\n",
    "print(bagging_clf)\n",
    "print(classification_report(y_test, bagging_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Over sampling\n",
    "Since the data is imbalanced for the '1' class we utilise a random oversampler to balance the data by duplicating existing data from the '1' class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('svm_clf', SVC(C=0.1, degree=1, gamma=0.1, random_state=2))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92       114\n",
      "           1       0.47      0.88      0.61        16\n",
      "\n",
      "    accuracy                           0.86       130\n",
      "   macro avg       0.72      0.87      0.76       130\n",
      "weighted avg       0.92      0.86      0.88       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_cols = ['symptom6', 'symptom5', 'symptom4', 'symptom3', 'symptom2']\n",
    "df_dropped = df.drop(dropped_cols, axis=1)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = split(df_dropped)\n",
    "X_train, y_train= ros.fit_resample(X=X_train, y=y_train)\n",
    "best_svm = svm_validate(X_train, y_train, X_validate, y_validate)\n",
    "print(best_svm)\n",
    "print(classification_report(y_test, best_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Bagging Classifier on Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                                                 ('svm_clf',\n",
      "                                                  SVC(C=0.1, degree=1,\n",
      "                                                      gamma=0.1,\n",
      "                                                      random_state=2))]),\n",
      "                  random_state=2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93       114\n",
      "           1       0.50      0.88      0.64        16\n",
      "\n",
      "    accuracy                           0.88       130\n",
      "   macro avg       0.74      0.88      0.78       130\n",
      "weighted avg       0.92      0.88      0.89       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_cols = ['symptom6', 'symptom5', 'symptom4', 'symptom3', 'symptom2']\n",
    "#encoded_cols = ['country','location', 'symptom1', 'symptom3', 'symptom6', 'symptom5', 'symptom4','symptom2']\n",
    "encoded_cols = []\n",
    "df_encoded = encode(df.drop(dropped_cols, axis=1), encoded_cols)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = split(df_encoded)\n",
    "X_train, y_train= ros.fit_resample(X=X_train, y=y_train)\n",
    "dic = {'clf':[], 'recall':[]}\n",
    "c_values = [0.1, 1, 10, 100, 1000] \n",
    "gamma_values = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "degrees = np.arange(1, 11, 1)\n",
    "\n",
    "parameters = list(itertools.product(c_values, gamma_values, degrees))\n",
    "for c, gamma, degree in parameters:\n",
    "    rbf_kernel_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(C=c, gamma=gamma, degree=degree, random_state = 2))\n",
    "    ])\n",
    "    bagging_clf = BaggingClassifier(base_estimator=rbf_kernel_svm_clf, n_estimators=10, random_state=2)\n",
    "    bagging_clf.fit(X_train, y_train)\n",
    "    y_pred = bagging_clf.predict(X_validate)\n",
    "    recall = recall_score(y_validate, y_pred)\n",
    "    dic['clf'].append(bagging_clf)\n",
    "    dic['recall'].append(recall)\n",
    "df_scores = pd.DataFrame(dic)\n",
    "bagging_clf = df_scores.iloc[df_scores['recall'].idxmax(), 0]\n",
    "print(bagging_clf)\n",
    "print(classification_report(y_test, bagging_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Encoding\n",
    "First we attempt to fit the model without any changes to act as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_features=6, random_state=2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       114\n",
      "           1       0.67      0.88      0.76        16\n",
      "\n",
      "    accuracy                           0.93       130\n",
      "   macro avg       0.82      0.91      0.86       130\n",
      "weighted avg       0.94      0.93      0.93       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test = split(df)\n",
    "best_DT = DT_validate(X_train, y_train, X_validate, y_validate)\n",
    "print(best_DT)\n",
    "print(classification_report(y_test, best_DT.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "We then encode some of the categorical data in the dataset to attempt to improve the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_features=37, random_state=2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       114\n",
      "           1       0.65      0.69      0.67        16\n",
      "\n",
      "    accuracy                           0.92       130\n",
      "   macro avg       0.80      0.82      0.81       130\n",
      "weighted avg       0.92      0.92      0.92       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['location', 'country', 'symptom1', 'symptom2', 'symptom3', 'symptom4', 'symptom5', 'symptom6']\n",
    "df_encoded = encode(df, cols)\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = split(df_encoded)\n",
    "best_DT = DT_validate(X_train, y_train, X_validate, y_validate)\n",
    "print(best_DT)\n",
    "print(classification_report(y_test, best_DT.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing one-hot encoding on the data decreases the information gain of each column thus worsening the performance metrics of the model. Thus we use the encoding that was given in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Here we experimentally select features. After some experiments this is the best result. Some features were removed based on their low correlation with the data while others were removed after experimentally testing that their removal improved recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_features=3, random_state=2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       114\n",
      "           1       0.62      0.81      0.70        16\n",
      "\n",
      "    accuracy                           0.92       130\n",
      "   macro avg       0.80      0.87      0.83       130\n",
      "weighted avg       0.93      0.92      0.92       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_cols = ['symptom6', 'symptom5', 'symptom4']\n",
    "df_dropped = df.drop(dropped_cols, axis=1)\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = split(df_dropped)\n",
    "best_DT = DT_validate(X_train, y_train, X_validate, y_validate)\n",
    "print(best_DT)\n",
    "print(classification_report(y_test, best_DT.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging with Validation\n",
    "In this section, we utilise a bagging classifier to attempt to improve the recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'clf':[], 'recall':[]}\n",
    "criterion = ['entropy','gini']\n",
    "splitter = ['best','random']\n",
    "class_weight = ['balanced', None]\n",
    "max_features = [i for i in range(1,X_train.shape[1])]\n",
    "parameters = list(itertools.product(criterion, splitter, class_weight,max_features))\n",
    "for crit, splitter, weight, max_features in parameters:\n",
    "    DT = DecisionTreeClassifier(criterion = crit, splitter=splitter, class_weight=weight, random_state = 2, max_features = max_features)\n",
    "    bagging_clf = BaggingClassifier(base_estimator= DT, random_state=2)\n",
    "    bagging_clf.fit(X_train, y_train)\n",
    "    y_pred = bagging_clf.predict(X_validate)\n",
    "    recall = recall_score(y_validate, y_pred)\n",
    "    dic['clf'].append(bagging_clf)\n",
    "    dic['recall'].append(recall)\n",
    "df_scores = pd.DataFrame(dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced',\n",
      "                                                        criterion='entropy',\n",
      "                                                        max_features=7,\n",
      "                                                        random_state=2),\n",
      "                  random_state=2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       114\n",
      "           1       0.93      0.81      0.87        16\n",
      "\n",
      "    accuracy                           0.97       130\n",
      "   macro avg       0.95      0.90      0.92       130\n",
      "weighted avg       0.97      0.97      0.97       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bagging_clf = df_scores.iloc[df_scores['recall'].idxmax(), 0]\n",
    "print(bagging_clf)\n",
    "print(classification_report(y_test, bagging_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling\n",
    "Since the data is imbalanced for the '1' class we utilise a random oversampler to balance the data by duplicating existing data from the '1' class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_features=2, random_state=2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       114\n",
      "           1       0.81      0.81      0.81        16\n",
      "\n",
      "    accuracy                           0.95       130\n",
      "   macro avg       0.89      0.89      0.89       130\n",
      "weighted avg       0.95      0.95      0.95       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_cols = ['symptom6', 'symptom5', 'symptom4', 'symptom3', 'symptom2']\n",
    "df_dropped = df.drop(dropped_cols, axis=1)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = split(df_dropped)\n",
    "X_train, y_train= ros.fit_resample(X=X_train, y=y_train)\n",
    "best_DT = DT_validate(X_train, y_train, X_validate, y_validate)\n",
    "print(best_DT)\n",
    "print(classification_report(y_test, best_DT.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Bagging Classifier on Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced',\n",
      "                                                        criterion='entropy',\n",
      "                                                        max_features=2,\n",
      "                                                        random_state=2),\n",
      "                  random_state=2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       114\n",
      "           1       0.93      0.88      0.90        16\n",
      "\n",
      "    accuracy                           0.98       130\n",
      "   macro avg       0.96      0.93      0.95       130\n",
      "weighted avg       0.98      0.98      0.98       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_cols = ['symptom6', 'symptom5', 'symptom4', 'symptom3', 'symptom2']\n",
    "encoded_cols = []\n",
    "df_encoded = encode(df.drop(dropped_cols, axis=1), encoded_cols)\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = split(df_encoded)\n",
    "X_train, y_train= ros.fit_resample(X=X_train, y=y_train)\n",
    "\n",
    "dic = {'clf':[], 'recall':[]}\n",
    "criterion = ['entropy','gini']\n",
    "splitter = ['best','random']\n",
    "class_weight = ['balanced', None]\n",
    "max_features = [i for i in range(1,X_train.shape[1])]\n",
    "\n",
    "parameters = list(itertools.product(criterion, splitter, class_weight,max_features))\n",
    "\n",
    "for crit, splitter, weight, max_features in parameters:\n",
    "    DT = DecisionTreeClassifier(criterion = crit, splitter=splitter, class_weight=weight, random_state = 2, max_features = max_features)\n",
    "    bagging_clf = BaggingClassifier(base_estimator= DT, random_state=2)\n",
    "    bagging_clf.fit(X_train, y_train)\n",
    "    y_pred = bagging_clf.predict(X_validate)\n",
    "    recall = recall_score(y_validate, y_pred)\n",
    "    dic['clf'].append(bagging_clf)\n",
    "    dic['recall'].append(recall)\n",
    "\n",
    "df_scores = pd.DataFrame(dic)\n",
    "bagging_clf = df_scores.iloc[df_scores['recall'].idxmax(), 0]\n",
    "print(bagging_clf)\n",
    "print(classification_report(y_test, bagging_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
